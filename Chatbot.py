import streamlit as st
import pandas as pd
from langchain_core.messages.chat import ChatMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser

# API KEYë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼
from dotenv import load_dotenv

# API KEY ì •ë³´ë¡œë“œ
load_dotenv()

st.title("ì°¸ìŠ¤í† ì–´ ì£¼ë¬¸ ê²€ìƒ‰ ì±—ë´‡")

# CSV íŒŒì¼ ì—…ë¡œë“œí•˜ê¸°
uploaded_file = st.file_uploader("CSV íŒŒì¼ ì—…ë¡œë“œ", type="csv")
if uploaded_file:
    df = pd.read_csv(uploaded_file, encoding="utf-8-sig")


# ìŠ¤íŠ¸ë¦¼ë¦¿ì€ ë§¤ë²ˆ ìƒˆë¡œê³ ì¹¨í•˜ëŠ” ê°œë…ì´ë¯€ë¡œ, ifë¬¸ì„ í†µí•´ messagesê°€ ë¹„ì—ˆì„ ë•Œ ì²˜ìŒ 1ë²ˆë§Œ ì‹¤í–‰í•˜ê²Œ ë§Œë“¬
if "messages" not in st.session_state:
    # ëŒ€í™”ê¸°ë¡ì„ ì €ì¥í•˜ê¸° ìœ„í•œ ìš©ë„ë¡œ ìƒì„±í•œë‹¤.
    st.session_state["messages"] = []

# ì‚¬ì´ë“œë°” ìƒì„±
with st.sidebar:
    # ì´ˆê¸°í™” ë²„íŠ¼ ìƒì„±
    clear_btn = st.button("ëŒ€í™” ì´ˆê¸°í™”")


# ì´ì „ ëŒ€í™”ë¥¼ ì¶œë ¥
def print_messages():
    for chat_message in st.session_state.messages:
        st.chat_message(chat_message["role"]).write(chat_message["content"])


# ì´ˆê¸°í™” ë²„íŠ¼ì´ ëˆŒë¦¬ë©´...
if clear_btn:
    st.session_state["messages"] = []

# ì´ì „ ëŒ€í™” ê¸°ë¡ ì¶œë ¥
print_messages()


# ìƒˆë¡œìš´ ë©”ì„¸ì§€ë¥¼ ì¶”ê°€
def add_message(role, message):
    st.session_state["messages"].append(ChatMessage(role=role, content=message))


# ê²€ìƒ‰ ê¸°ëŠ¥ ì •ì˜
def search_orders(query, df):
    keywords = query.strip().split()
    mask = pd.Series([True] * len(df))  # AND ì¡°ê±´ì´ë¯€ë¡œ ì²˜ìŒì—” ëª¨ë‘ True
    for kw in keywords:
        mask = mask & (
            df["ì£¼ë¬¸ìëª…"].astype(str).str.contains(kw, case=False, na=False)
            | df["ìƒí’ˆëª…(í•œêµ­ì–´ ì‡¼í•‘ëª°)"]
            .astype(str)
            .str.contains(kw, case=False, na=False)
            | df["ì£¼ë¬¸ì¼ì‹œ"].astype(str).str.contains(kw, case=False, na=False)
        )
    return df[mask]


def chat_with_gpt(prompt):
    response = client.chat.completions.create(
        model="gpt-4-turbo", messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content


# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# ì±„íŒ… ê¸°ë¡ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥
if prompt := st.chat_input(
    "ì£¼ë¬¸ìëª…, ìƒí’ˆëª…, ì£¼ë¬¸ì¼ì‹œ ì¤‘ ì•„ë¬´ê±°ë‚˜ ì„ì–´ì„œ ì…ë ¥í•´ë³´ì„¸ìš”!"
):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # ê²€ìƒ‰ ì‹¤í–‰
    search_results = search_orders(prompt, df)
    if not search_results.empty:
        response_text = f"ğŸ” {len(search_results)}ê±´ì˜ ê²°ê³¼ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤:\n"
        response_text += search_results[["ì£¼ë¬¸ë²ˆí˜¸", "ì£¼ë¬¸ìëª…", "ì£¼ë¬¸ì¼ì‹œ", "ìƒí’ˆëª…(í•œêµ­ì–´ ì‡¼í•‘ëª°)"]].to_markdown(index=False)

    else:
        response_text = "ğŸ˜¢ í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” ì£¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤"

    # AI ì‘ë‹µ í‘œì‹œ
    with st.chat_message("assistant"):
        st.markdown(response_text)
    st.session_state.messages.append({"role": "assistant", "content": response_text})
